---
title: 統計の話をしようじゃないか - ソフトウェア品質のための統計入門（No.13 相関と因果：散布図と相関係数の落とし穴）
author: shuichi-takatsu
date: 2025-06-12
tags: [Analytics, ソフトウェア, 品質, 新人向け]
image: true
---

## はじめに

これまでの連載では、**平均**や**割合**といった代表値を通じて、「母集団の傾向を推定する」手法について解説してきました。  
具体的には、標本平均から母平均を推定したり、割合の差を比較したりといった場面で、**統計的推定**や**仮説検定**を用いる方法を取り上げてきました。

しかし実務では、「ある要因が別の結果に影響を与えているのか？」という、よりダイナミックな関係性に注目したい場面も少なくありません。  
たとえば――

- 「レビュー工数が増えると、不具合は減るのか？」
- 「コードの複雑度が高いと、欠陥が多くなるのか？」

こうした問いに対して、「関係があるかどうか」を探るのが**相関分析**です。  
ただし、相関があるからといって、必ずしも「因果関係がある」とは限りません。  
そこには**交絡因子**や**見せかけの相関**といった注意点も存在します。

また、「統計的に有意かどうか」だけでなく、**その関係が実務的に意味のある大きさかどうか**を知るには、**効果量（Effect Size）** という視点が欠かせません。  
P値に加えて効果量を評価することで、数字の背後にある「実務へのインパクト」をより明確に把握できます。

「統計の話をしようじゃないか」第13回では、以下のトピックに焦点を当てて進めていきます：

- 相関と因果の違い  
- 相関係数の意味と解釈  
- 効果量（Effect Size）の実務的な意義  
- 散布図による関係性の可視化と注意点  
- 偏相関と交絡因子の対処  

ソフトウェア品質データを例にとりながら、「関係はあるけれど、それは本当に意味があるのか？」という視点を持つことで、より実践的で信頼性の高い判断ができるようになることを目指します。

---

## 相関とは何か？

**相関**とは、2つの変数の間に「一緒に動く傾向」がある状態を指します。  
たとえば、「開発規模が大きいほど不具合数が増える」といった関係があれば、「開発規模」と「不具合数」の間に相関があるといえます。

### ● 相関の基本的な特徴

- 相関は因果関係を意味しません（後述）。
- 正の相関：一方が増えると他方も増える傾向（例：開発規模と工数）。
- 負の相関：一方が増えると他方が減る傾向（例：レビュー時間と不具合混入率）。
- 相関は散布図で視覚的に確認でき、数値化には**相関係数（ピアソンのr）** を用います。

### ●  相関係数の目安

相関係数 $r$ は、-1から+1までの値を取り、以下のように解釈されます。

| 相関係数 $r$ | 解釈例               |
|--------------|----------------------|
| ±0.9以上     | 非常に強い相関        |
| ±0.7〜0.9     | 強い相関              |
| ±0.4〜0.7     | 中程度の相関          |
| ±0.2〜0.4     | 弱い相関              |
| ±0〜0.2       | ほとんど相関なし      |

この目安はあくまで参考であり、**実務においては文脈やデータ特性に応じた解釈**が重要です。

### ● ソフトウェア品質の相関例

- **不具合検出数と開発期間の相関**  
  開発期間が長くなるほど不具合が多くなる傾向が見られる場合、正の相関があると考えられます。
  
- **コード複雑度と欠陥密度の相関**  
  サイクロマティック複雑度が高いモジュールほど欠陥密度が高くなるなら、強い正の相関が示される可能性があります。

- **レビュー時間と修正漏れ数の相関**  
  レビュー時間が長いと修正漏れが少なくなるという傾向がある場合、負の相関（負のr値）を示すかもしれません。

相関係数は「傾向の強さ」を示す指標であり、実務では**P値とセットで使う**ことで「統計的な有意性」と「実務的な効果量」を両方確認できます。  
（ツールを使った相関係数の説明を [こちら](/blogs/2022/05/26/correlation-matrix/) の記事で紹介していますので参考にしてください）

---

## 効果量（Effect Size）

**効果量**とは、「観測された差の大きさ」や「相関の強さ」を数量的に表す指標です。  
P値が「偶然かどうか」を示すのに対して、効果量は「差や関係がどれほど大きいか」を評価するために用いられます。

### ● なぜ効果量が重要なのか？

- **P値が有意でも、効果量が小さい**場合、実務的には無視できるような差である可能性があります。
- **効果量はサンプルサイズに依存しない**ため、「実際に意味のある違いかどうか」を判断するのに有効です。

### ● 主な効果量の例

| 効果量指標 | 用途と意味                                |
|-------------|---------------------------------------------|
| Cohen's d   | 平均値の差の大きさ（t検定で使用）             |
| Pearson's r | 変数間の相関の強さ（相関分析で使用）          |
| η²（イータ²）| 群間の差の説明力（分散分析で使用）            |
| オッズ比（OR）| カテゴリ間の関係性の強さ（ロジスティック回帰など） |

### ● ソフトウェア品質における効果量の活用例

たとえば、「新しいツールを導入したことで、不具合数が統計的に有意に減少した」と報告されたとします。  
一見すると良い結果に見えますが、もしその差がわずかで、効果量がごく小さい場合、実際の開発現場ではユーザーにとって体感できるような違いではないかもしれません。  
このように、**P値が有意であっても「実務的な改善」として意味があるかは別問題**です。

一方で、**P値が有意ではなかったとしても、効果量が中程度〜大程度といった大きさを持っている場合、それは単にサンプルサイズが足りなかっただけで、実際には重要な差がある可能性**もあります。

このように、効果量は「統計的な有意性（P値）」とは独立したもう一つの判断軸として機能します。  
**P値と効果量の両方を併せて示すことが、実務における判断の説得力を高めるためのポイントとなります。**

### ● t検定の効果量（Cohen's d）の具体例

たとえば、あるプロジェクトで次のような調査を行ったとします。

- Aチーム（旧ツール使用）：不具合報告数の平均 = 8.4、標準偏差 = 2.0、n = 30  
- Bチーム（新ツール使用）：不具合報告数の平均 = 6.8、標準偏差 = 2.1、n = 30

このとき、Cohen's d は以下のように計算されます。

・Cohen's d の計算式：  

$$
d = \frac{M_1 - M_2}{s_p}
$$

ただし、$s_p$（プールされた標準偏差）は以下とします。  

$$
s_p = \sqrt{\frac{s_1^2 + s_2^2}{2}} = \sqrt{\frac{2.0^2 + 2.1^2}{2}} \approx 2.05
$$

よって Cohen's d は次のように計算できます。  
$$
d = \frac{8.4 - 6.8}{2.05} \approx 0.78
$$

この結果は **Cohen's d = 0.78** であり、一般的な基準では「**中程度〜強い効果**」に相当します。  
P値とあわせてこの効果量を示すことで、「統計的に有意」なだけでなく、「実務的にも意味のある改善」であることを補強できます。

:::info
・Cohen's d の効果量の解釈（目安）を以下に示します。  
| Cohen's d の値 | 効果量の大きさの解釈            |
|----------------|------------------------------|
| 0.0 ～ 0.2      | ごく小さい効果（ほとんど差がない） |
| 0.2 ～ 0.5      | 小さい効果（わずかな差）         |
| 0.5 ～ 0.8      | 中程度の効果（実務的に意味がある差）|
| 0.8 以上        | 大きい効果（明確で大きな差）       |
:::

---

## 散布図の活用

散布図は、2つの変数の関係性を視覚的に把握するための基本的かつ強力なツールです。  
数値だけでは見えにくい特徴を“目で見る”ことで、相関や傾向、外れ値の有無などを直感的に理解できます。

- **点のばらつき方**から、変数間の関係の強さや方向（正の相関／負の相関／無相関）を把握できます。
- 線形関係に限らず、**曲線的な非線形の傾向**や**群ごとの分布の偏り**なども視認できます。
- **外れ値の存在**も一目でわかり、相関係数の信頼性に影響する可能性を察知するのに有効です。

### ● ソフトウェア品質における例

たとえば、モジュールのサイズ（コード行数）と不具合数の関係を散布図で可視化したとします。  
ある程度の相関があるように見えても、数個の極端に大きなモジュールが強い影響を与えている場合、  
散布図を見れば「外れ値」の存在にすぐ気づくことができます。

また、直線的な相関がなさそうに見えても、散布図によって「ある範囲だけ相関が強い」や「U字型の関係がある」など、  
数値指標だけでは見落としがちな特徴を捉えるヒントにもなります。

![コード行数と不具合数の関係](https://gyazo.com/9675a2dc7a3bc6fb60cef478c92ff1a2.png)

> 数字（相関係数）とセットで“絵（散布図）”を見ることで、より多角的で妥当な判断が可能になります。

---

## 相関分析の基礎

散布図や相関係数は、「なんとなく関係ありそう」という感覚を裏付けるための視覚的・定量的な手段ですが、もう一歩進んで「統計的に有意な相関があるか？」を判断したいときには、**相関分析**を使います。

### ● ピアソンの積率相関係数と検定

相関係数（ピアソンの *r*）は、「2つの変数の線形な関係の強さ」を表す指標で、-1から+1の範囲をとります。  
これに対して「この *r* は、たまたま得られたサンプルで偶然観測されたものではなく、母集団でも有意な相関があるのか？」  
を検定するのが、**相関係数の有意性検定**です。

この検定では、以下のような仮説を立てます：

- 帰無仮説（$H_0$）：母集団の相関係数 $\rho = 0$（つまり、相関は存在しない）
- 対立仮説（$H_1$）：$\rho \ne 0$（相関がある）

P値が有意水準（例：5%）未満であれば、「相関がある」と判断します。

### ● 実務での相関分析の例（ソフトウェア品質）

たとえば、以下のような疑問に答える際に相関分析は有効です：

- 「開発期間と不具合件数に、統計的に意味のある関係はあるのか？」
- 「レビュー工数と欠陥密度の関係は、偶然ではなく一貫性があるのか？」
- 「テストカバレッジと品質指標の相関は、再現性があるのか？」

ただし、相関分析を行う前提としては「データが**連続変数**であり、**正規分布に近いこと**」が求められます。  
これが満たされない場合は、スピアマンの順位相関などノンパラメトリック手法を検討する必要があります。

---

## 「偏相関」とは

**偏相関（Partial Correlation）** とは、3つ以上の変数があるときに、ある2つの変数の間の相関関係を、他の変数の影響を除外したうえで評価する指標です。

たとえば――

- **X：開発工数**
- **Y：欠陥件数**
- **Z：モジュールの規模（行数）**

このとき、XとYの相関を見たとしても、それがZ（モジュール規模）によって引き起こされた見せかけの相関かもしれません。  
そこで「Zの影響を除いたうえで、XとYにまだ相関があるか？」を見たいときに使うのが偏相関です。

### ● 通常の相関との違い

| 種類        | 説明                                      |
|-------------|-------------------------------------------|
| 相関係数     | XとYの単純な相関を見る                    |
| 偏相関係数   | Zの影響を除いたうえでのXとYの相関を見る   |

### ● ソフトウェア品質の文脈での活用例

たとえば――

- 「レビュー工数」と「不具合件数」に相関があるように見えても、「モジュール規模」の影響かもしれない。
- 偏相関を使うことで、「モジュール規模の影響を取り除いたあとでも、レビュー工数が欠陥に影響しているか？」を検証できる。

このように、**偏相関は「見せかけの相関」に惑わされないための有効な手段**です。  
（ツールを使った偏相関の説明を [こちら](/blogs/2022/07/08/partial-correlation/) の記事で紹介していますので参考にしてください）

---

## 「相関」と「因果」は違う！

相関があるということは、「2つの変数が一緒に変化する傾向がある」という事実を示すだけで、**片方がもう一方を引き起こしている（＝因果関係がある）とは限りません**。

たとえば――

- **レビュー指摘数と不具合件数に相関がある**とします。  
  しかし、それだけで「レビューが多いと不具合が減る（または増える）」とは**言い切れません**。
- **第三の要因（交絡因子）**が存在する可能性があるのです。  
  たとえば、「仕様の複雑さ」がレビューも不具合も両方に影響していたとしたら、これは**複雑さという別の要因によって見かけ上の相関が生まれている**にすぎない可能性があります。

### ● 相関と因果の混同が招くリスク

- 相関を因果と誤解して改善策を打つと、**本質的な問題に手を打てない**可能性があります。
- **「レビューを増やせばバグが減るはずだ」** という施策が、実は「複雑な仕様ではレビューもバグも増えてしまう」だけだった、ということも。

### ● 対策：因果関係の可能性を見極めるには？

- 偏相関を使って第三の変数の影響を取り除く
- 時系列データで「どちらが先に変化したか」を検討する
- 実験や介入設計（ABテストなど）を通じて因果を確認する

> **まとめ：** 相関は有用な情報ですが、「因果」かどうかの判断には注意が必要です。  
> データに基づく意思決定では、**因果を示す証拠があるかどうか**を意識して見極めましょう。

:::info
アイスクリームと溺死者の関係？ 〜相関と因果の誤解〜

ある有名な例に、こんな話があります。

> **「アイスクリームの売上が増えると、溺死者数も増える」**

このデータには**確かに相関関係がある**のですが、だからといって「アイスクリームを食べると人が溺れる」わけではありませんよね。

このようなケースでは、**第三の要因（交絡因子）** が存在します。  
この場合、それは **「暑い日」** です。

- 暑い日はアイスクリームがよく売れる
- 同じく暑い日は海水浴などで水辺の活動が増え、溺水事故が起きやすくなる

つまり、**「暑い日」という要因が両方の変数に影響している**のです。
このように：

- **相関がある**からといって  
- **片方がもう片方を引き起こしている（＝因果関係）** とは限らない

ということを、データ分析では常に意識する必要があります。

> **相関 ≠ 因果** ―― 「一緒に変動する」ことと「原因と結果である」ことは別物です。
:::

---

## 実務での注意点

- **相関を因果と誤解して対策を立ててしまうと、的外れで誤った施策**になる危険があります。  
  たとえば、レビュー数と不具合数に負の相関があったからといって、レビュー数だけを機械的に増やしても、根本原因にアプローチできていない可能性があります。

- **「相関がある」だけでは、何が原因で何が結果かは分かりません**。  
  さらに、**交絡因子（第三の要因）** が関与している場合、表面的な相関だけで意思決定すると本質を見誤るおそれがあります。

- したがって、まずは「観察的に相関があるかどうか」を確認し、次に **「実験や設計」によって因果関係を検証する** ステップが重要です。  

:::info
相関はヒントに過ぎません。「相関があるから対策をとる」ではなく「相関から仮説を立てて、因果を検証する」ことが、実務における健全な統計リテラシーです。
:::

---

## まとめ

- 相関とは「一緒に変動する傾向」を示すものであり、因果関係とは異なります。
- 相関係数（Pearsonのr）は、2つの変数の直線的な関係の強さを数値で示す指標です。
- 相関が強いからといって「AがBを引き起こしている」とは限らず、交絡因子が関係している可能性もあります。
- 実務で相関を見つけたら、**すぐに因果と決めつけず、実験や設計を通じて検証する姿勢**が重要です。
- 効果量（例：Cohen's d）や散布図などを併用することで、**実務にとって意味のある差や関係**をより深く理解できます。

---

## 次回予告

次回は **「予測：回帰分析で品質を読み解く」** をお届けします。  
相関よりさらに一歩進んで、「予測」や「影響の度合い」をモデル化する手法です。  

実務での活用も多い分析手法ですので、ぜひご期待ください。

[こちらに統計関連情報をまとめています。](/analytics/)

データ分析にご活用いただければ幸いです。

<style>
img {{
    border: 1px gray solid;
}}
</style>
