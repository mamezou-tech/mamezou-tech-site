---
title: マイクロサービスなアプリを動かすAWS環境を1日50円で作ってみた
author: toshio-ogiwara
date: 2023-05-28
tags: [AWS, msa, java]
---
今回は[「MicroProfileのサンプルリニューアル – 今度はほんとにMSA」](/msa/mp/cntrn19-mp-sample-renewal/)の番外編として記事のサンプルアプリを動作させるために構築したケチケチAWS環境を紹介したいと思います。業務で使う本番環境としてはでははっきり言って使い物にならないですが、変わったことに労力使う人もいるのネ程度に生暖かく読んでもらえればと思います。

:::alert: 利用料は自分でも確認しましょう！
記事は執筆時点(2023/5/27)の情報をもとにしています。クラウドサービスの料金体系は頻繁に改訂されます。また、取り上げる情報の正確性については十分確認を行っていますが、筆者の理解が間違っている可能性もあります。お金が絡むことなのでクラウドサービスを利用する際は料金体系をご自身でも確認されることをお勧めいたします。
:::

# 動作させるMSAなアプリ
まずお題となるケチケチ環境で動かすのは[「MicroProfileのサンプルリニューアル – 今度はほんとにMSA」](/msa/mp/cntrn19-mp-sample-renewal/)で紹介した次のアプリです。

![overview](/img/mp/19-service-overview.drawio.svg)

このアプリを動かすために必要となる環境を整理すると次のとおりになります。

|要素|必要な環境|
|-----|------------|
|SPAクライアント|静的webページのホスティング|
|CLIクライアント|（ローカル環境で動かすので今回の対象外）|
|ApiGateway |コンテナ実行環境 |
|RentalItemService |コンテナ実行環境 |
|ReservationService|コンテナ実行環境 |
|UserService|コンテナ実行環境 |

なお、DBはh2のインメモリデータベースを使ったDatabase per Service構成のため、それ用の実行環境は不要です。また、その他、サンプルアプリの詳細は[こちら](https://github.com/extact-io/msa-rms-parent)にまとめてあります。

# 構築環境のポリシー
今回の記事のテーマにもなっていますが、このMSAなアプリを動作させる環境として次のことをポリシーとしました。

-	データを管理するサービスはPrivate subnetに配置することのみを必須
-	可用性やセキュリティなどのその他の要素についてはコストを最優先

さすがにデータを管理するサービスやDBをPublic subnetで曝すのはデモサイトとしても抵抗があるのと、環境構築の難易度が低すぎになるので、データを管理するサービスはPrivate subnetに配置することを必須とし、それ以外は自腹個人アカウントを使うのでコスト優先にして考えることにしました。そのため、構築した環境はシングルAZ構成で高額なALBも利用していません。

# 結論、作った環境はこうなった
結論から先に説明するとこのポリシーをもとに次のような構成とすることで1日50円で運用できる環境を作ることができました。

![aws-arch](/img/blogs/2023/0528-01_aws_arch.drawio.svg)

構成はコスト最優先のためシングルAZ構成にしています。また詳細は後述しましたが高額になるALB(Application Load Balancer)も利用していません。

# 安く上げるための考慮ポイント
いきなりAWSの全体構成をだされても、なんでそうなの？がわからないと思うので、ここからは安く上げるために、あえて普通じゃない、もしくは工夫したポイントを個別に説明してきます

## ApiGatewayにはALBを使わずに済むEC2を採用
コンテナ実行環境は自分で何個もEC2インスタンスを管理するのは面倒でイヤなのでECS Fargateにすることを考えていた。が、それには１つ悩ましい問題があった。それはVPCに入ってくるリクエストをどのようにECSタスクにルーティングするかだ。

今回のサンプルの例でいえば、外部からのリクエストは各サービスの前段にいるApiGatewayサービスへルーティングする必要があるが、FargateのECSタスクにはElasticIP(固定パブリックIPアドレス)を割り当てることはできない。

このため、次のようにECSタスクの前段にALB(Application Load Balancer)を置き、ALB経由でECSタスクにリクエストをルーティングさせるのがスタンダードです。また、ALBを使うことでSSL/TSL証明書の発行も無料でACM(AWS Certificate Manager)で行えるためとても便利です。

![alb](/img/blogs/2023/0528-02_alb-fargate.drawio.svg)

そんな素敵なALBですが、最大のネックは料金です。ALBは稼働時間と利用料に応じた従量制料金が発生します。また、EC2やECSタスクは利用していないときは停止することで料金の発生を抑えることができますが、ALBは削除しない限り料金が発生し続けます。このため、１か月単に稼働させただけで$16.2(=0.0225[時間単価]x 30[日]x24[時間])となり130円換算で最低2100円発生します。これに使った分だけの従量課金が加算されるので、個人アカウントでは心配でオチオチ使っていられません。

このため、最前列に配置するApiGatewayサービスだけはFargateにするのは諦め、ElasticIPで固定IPを割り当てたEC2上にDockerをインストールし、そのDocker上でApiGatewayサービスを稼働させることにしました。この場合、ACM によるSSL/TSL証明書の発行は行えないため、無料で使えるLet's Encryptで証明書を発行するようにしています。

![ec2](/img/blogs/2023/0528-03_ec2-.drawio.svg)

## NATインスタンスでコンテナイメージをpullする
外部からVPC内へのルーティングはEC2で一段落しましたが、次に問題となるのがVPC内から外部への通信です。

冒頭でも触れたように、コストを最優先にするといってもデータを管理するサービスだけはPrivate Subnetに配置するとしました。このため、Private Subnetでコンテナサービスを起動させるのですが、これにはコンテナイメージを取得するために、コンテナレジストリへのアクセスが必要となります。

が、しかし、候補となりえるコンテナレジストリのECR、GitHub PackagesともVPC内にはありません。このため、Private Subnetに配置されたコンテナサービスからVPCの外部にあるコンテナレジストリになんらかの方法でアクセス可能に必要があるのですが、この手段として一般的に用いられるのがVPNエンドポイント(PrivateLink)を使ってECRにアクセス可能にするか、NATゲートウェイを使ってインターネット経由でECRもしくはGitHub Packagesにアクセス可能にするの２つです。

![vpcendpoint](/img/blogs/2023/0528-04_vpc-endpoint-.drawio.svg)
![natgateway](/img/blogs/2023/0528-05_natgateway-.drawio.svg)

VPNエンドポイントはエンドポイントごとに料金が発生するというデメリットがありますが、インターネットを経由することなくプライベート接続でターゲットのエンドポイントにアクセスすることができるメリットがあります。

対してNATゲートウェイはNATゲートウェイを経由させればVPC外のどこへでもアクセスすることが可能になりますが、インターネット回線を経由するというデメリットがあります。

今回は、セキュリティは必要最低限でよいので、安ければVPNエンドポイントとNATゲートウェイのどちらでもよいのですが、どちらとも個人で使うには高すぎました・・

VPCエンドポイント、NATゲートウェイともに料金体系はALBと同様に稼働時間と利用量に応じた従量制料金で課金を止める方法も削除しかありません。ぞれぞれの１か月間の時間課金は次のようになります。

-	VPCエンドポイントは$7.2(=0.01[時間単価]x 30[日]x24[時間])
-	NATゲートウェイは$32.4(=0.045[時間単価]x 30[日]x24[時間])

料金的にNATゲートウェイはなにもしなくても月に4000円程度(130円換算)掛かるので選択肢にはなり得ません。VPCエンドポイントは時間課金に加えてエンドポイントを流れたデータ量に応じた料金が発生しますが、つなぐ先はECRのため、相当量のデータが流れる可能性もあります。このため、使うには少し勇気が必要です。

そこで、他にいい手はないかと考えて思いついたのが古き良き手法のNATインスタンスです。昔はNATインスタンス用のEC2イメージが提供されていましたが今は提供されていません。このため、NATインスタンスといってもその名のサービスがあるわけでなく単にEC2インスタンスに自分でiptablesをインストールし、次のようにPublic SubnetとPrivate Subnet間のルーティング設定をしたEC2インスタンスになります。

![natgateway](/img/blogs/2023/0528-06_natinstance-.drawio.svg)

今回はそもそもApiGatewayサービスはPublic SubnetのEC2で稼働させることにしていたので、そのEC2にiptablesをインストールと設定をすればよいだけので、実質追加コストゼロで対応できます🙌

## スポットインスタンスの利用
これが料金を抑えるのに一番効果を発揮している手段です。EC2やECSタスクを実行するのに割り当てられたリソースは自分たちが解放するまで占有して使うことができますが、スポットインスタンスはAWSの空きリソースを使って稼働させるものになります。スポットインスタンスは通常料金の最大90%(大体70%程度)で利用することができますが、空きリソースを使っているため、空きリソースがない場合や他に優先すべきものがある場合、AWSの都合である時インスタンスが停止されるデメリットがあります。逆にそれ以外はまったく通常のインスタンスと同じです。

このため、プロダクション環境では使うことが躊躇われますが、今回のようなデモ環境や開発環境用途の利用で困ることはありません。

ということで、今回アプリを実行させているEC2の 1インスタンスとFargateのECSの3タスクともすべてスポットインスタンスを使って稼働させています。

ちなみにですが、2か月くらいスポットインスタンスを使っていますが、アマゾンさんから停止のお手紙をもらったことはまだありません。

## コンテナレジストリにはGitHub Packagesを使う
ECRは管理するコンテナイメージのデータ量に応じて料金が課金されます。これに対してGitHub Packages(正確にはGitHub Packages Container registry)はパブリックイメージであればどれだけ使っても無料[^1]です。

GitHub Packagesはパッケージの公開範囲がパブリックでもそのダウンロードにはGitHubの認証が必要となるため、使い勝手が悪くコンテナレジストリとして使うのを敬遠されがちでしたが、コンテナイメージに限ってはパブリックであればGitHubの認証なくコンテナイメージをダウンロードすることができ使い勝手に問題はありません。

したがって、コストだけを考えてパブリックなコンテナイメージを管理するのであれば、どれだけ使っても無料なGitHub Packagesに軍配があがります。

![githubpackages](/img/blogs/2023/0528-07_use-githubpackages.drawio.svg)

ただし、今回はコスト優先のため無視していますが、AWS上で使うことを前提にした場合、セキュリティ面では次に挙げるとおりECRに圧倒的に軍配があります。

-	他のAWSサービスと同様IAMでコンテナイメージの取得等を制限できる
-	ECRはコンテナイメージに対する脆弱性スキャンを無料で簡単に使うことができるが、GitHub Packagesを使う場合は、GitHub Actionsで外部サービスを組み込んで利用する必要がある
-	コンテナレジストリのエンドポイントはGitHub Packages とECRのどちらともVPC外になるが、ECRはVPCエンドポイント使うことでインターネット網を経由せずコンテナイメージの取得をすることができるが、GitHub Packagesは原則インターネット網経由となる

今回は用途がデモサイトのためセキュリティに関する考慮はある程度無視できるため、コスト優先のGitHub Packagesを採用しましたが、業務で利用する場合など一定のセキュリティが求められる環境ではECRを使うのが一般的です。

[^1]: [GitHubパッケージの支払いについて - GitHub Docs](https://docs.github.com/ja/billing/managing-billing-for-github-packages/about-billing-for-github-packages)

## CI/CDはAWSのCodeシリーズではなくGitHub Actionsを使う
コンテナレジストリにGitHub Packagesを使うことにしたので、CI/CDにはGitHub Actionsを悩まず使うことにしました。[^3]
[^3]: CodeDeployだけはコミットハッシュのコンテナイメージを起動するように書き換えたシェルスクリプトをAWS CodeDeployでEC2にデプロイし、

CodeDeployはそもそもAWS内へのデプロイはいくらつかっても無料で、CodeCommitも今回の個人用途であれば無料枠に収まる範囲だと思いますが、CodeBuildとCodePipeline
は少し微妙です。CodeBuildは一定のビルド時間までは無料ですが、それ以上は料金がかかります。実際問題金額は大した額じゃないので、問題ないのですが、ビルドする度に今月はまだそれほど使ってないよな・・とか思うのは精神衛生上よろしくありません。CodePipelineも１本は無料ですが、それ以降は料金が発生します。

これに対して、GitHubはGitもActionsもどれだけ使ってもパブリックであれば無料です。最初にGitHub Packagesを使うからCI/CDは無条件にGitHub Actionsといいましたが、この前提がなくフラットに考えても今回の用途ではGitHub Actionsを選択したと思います。

![githubpackages](/img/blogs/2023/0528-08_cicd.drawio.svg)



じゃ、AWSのCodeシリーズにいいところはないのか？というとそんなことはなく、GitHub Packagesの選定と同じように、AWSのCodeシリーズはそれぞれのサービスに対して権限管理をIAMで一元的にできるのと、AWSの閉域網内でタスクが完結するといったセキュリティ面での強みがあります。

## 使わない時間帯はGitHub Actionsを使ってサービスを止める
自分で使うにしても、他人に使ってもらうにしても深夜、早朝にサンプルアプリを使うことはまずありません。このため、深夜11時から翌9時まではGitHub Actionsのスケジュール起動で起動／停止するようにしています。AWSのサービスをスケジュール停止する方法としてAWS Lambda + CloudWatch Eventsをよく見かけますが、今回はGitHub ActionsのワークフローからAWS CLIを使って起動と停止を行っています。その理由はもちろん気兼ねなく無料で使えるからです。

# ケチケチ作戦を実施した結果の料金
ここまで書いた爪に火を点すようなケチケチ作戦を実施した結果、AWSを

-	EC2(t2) x 1スポットインスタンス x 24時間/日稼働[^2]
-	ECSタスク(0.25vCPU/0.5GB) x 3スポットタスク x 14時間(9時～23時)/日稼働

の条件で使った際に実際の日々のコストを次のようにすることができました。

[^2]: 前段のApiGatewayサービスは時間外のエラーをハンドリングしてユーザに通知する必要があるため24時稼働させています。

[キャプチャ]

グラフは執筆時の直近1週間のコストのグラフですが、結果は見てのとおり、ネットワーク系のコストが発生しない構成にし、EC2とECSタスクにスポットインスタンスを利用することで毎日$0.42(約50円)に抑えることができました。(5/22は深夜までデバックしたので時間を延長して使ったため)

実業務ではここに表れていないCloudWatchのコストが高くなりがちですが、今回はサンプルということもあり、それほど利用していないため、無料枠に収まっています。

# まとめ（そもそもなんでケチろうと思ったのか）
実践ではあまり訳に立たないケチケチ作戦を長々と紹介してみましたが、いかがでしたでしょうか？最後にケチった環境を作ろうと思った動機に少し触れて記事を終わりにしたいと思います。

筆者が所属する豆蔵には技術調査や自己啓発用途で自由に使えるAWS環境が用意されています。なので、この会社のAWS環境でアプリを動かす環境を作る選択肢もありましたが、それはせず今回は筆者の個人アカウントのAWS環境で構築を作ってみました。

その理由は、自腹でドキドキすることでAWSのコストも身にしてみて意識できるようになろう！ということでした。

会社で自由に使えるAWS環境は、豆蔵がエンジニアには優しい会社であることを反映してか、月額かなりな予算が割り当てられています。これはこれで何かを調査、検証する際にコストを気にしたり、都度予算を調整したりする必要がない恵まれた環境なのですが、その反面、コストに対する意識が低くなります。

実際のプロジェクトではコストに対する制約は必ずあり、コストの範囲内でベストな選択することやコストを抑えて運用することなどが必ず求められます。

このため、今回は少しはコストも気にして環境を作ってみよう！と思ったのですが、上述のとおり会社の環境では意識が甘くなるため、だったら、自腹で！と考え、個人アカウントで作ってみました。

で、実際やってみた結果ですが、高額なサービスや下手な使い方をすると万単位でお金が飛んでいくので、AWSの料金説明はよく見てコレでもか！くらいに調べるため、提供機能だけではなく料金体系についてもよく理解できるようなりました。

また、やりたいことがあってもそれを実現する代表的なサービスの料金が高い場合、自腹なので、他で代替できないか？などを自然に考えるようになるため、環境構築の選択肢が広がります。

なので、CostExploreを見るのがドキドキなこともあったりはしますが、ケチケチ運用でお金以上に得られるものはあったかなと思います。

