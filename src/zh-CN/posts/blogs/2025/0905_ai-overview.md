---
title: 门外汉对生成式 AI 的理解总结
author: shinichiro-iwaki
date: 2025-09-05T00:00:00.000Z
summerRelayUrl: https://developer.mamezou-tech.com/events/season/2025-summer/
tags:
  - 生成AI
  - summer2025
image: true
translate: true

---

这篇文章是2025夏季接力连载的第5篇。

最近生成式 AI 技术的进步令人瞩目，即使是笔者这样“AI？啊，就是《星〇大战》里的金色机器人”[^1]这种程度的认知水平，也已经能够在一定程度上利用 AI 来完成工作了。虽然“不太懂也能用”本身就是一种了不起的进化，但在这一行业——也就是生成式 AI 技术及其应用机制的提供方——工作时，至少对其大致框架有所了解总是好的。关于生成式 AI 的信息虽然很多，但也因为没能找到那些能让外行人也能易于理解概念[^2]的资料，笔者在初期学习时颇费苦心。于是，我想基于目前所能理解的内容，整理出一份能够“让人对生成式 AI 的世界观有个大致印象”的文章。

当然，由于笔者只是外行，本文内容是基于公开信息等学习后所作的总结，可能不够准确或包含一些误解。文章责任当然由笔者承担。

[^1]: 这可能是个不太好理解的玩笑，但我想大家都有小时候看电视或电影里机器人和人类对话的场景，然后不明所以地心想“那家伙就是 AI 吗？”并暗暗点头的经历。对了，写到这里我才意识到，由于技术普及，像 Siri、Alexa 这类都不再被称作 AI，反倒感觉最近越发少有人使用“AI”这一称呼了。

[^2]: 比如你听到“生成式 AI 是利用深度学习技术学习现有数据，并具有以更接近人类创作方式生成新内容的特色。”即使说了这么一番话，如果周边概念完全不清楚，就只会冒出“诶，电脑会学习是怎么回事？”或者“深度学习和生成新内容有什么关系？”之类的疑问符号一堆，对吧？（笔者就是如此。）

## 引言：生成式 AI 到底是什么？

“AI”这一词经常被使用，但能对“什么是 AI、什么不是 AI”以及“为何二者存在差异”这类提问给出严格答案的人，我想很少（或根本没有）吧。

AI 这一概念本身相当古老，可追溯到近百年前机械能够进行计算的时候。从《模仿游戏》中描绘的破译电码机之父 艾伦·图灵 ，到奠定早期计算机理论的 约翰·冯·诺依曼 等先驱时代起，就一直有人尝试让机器执行“人类的智能活动”。而在被称为 1965 年达特茅斯会议的研究发布会上，约翰·麦卡锡提出了“Artificial Intelligence（人工智能）”这一表达，据信这便是“AI”一词的由来。

笔者的理解是，对于“AI 是替代知能≒人类智能活动的机器”这一点，似乎并无异议。但究竟何为“智能”要给出严格定义却很困难，提倡者麦卡锡教授本人也承认“（在不与人类智能挂钩的前提下）严格定义智能”是一件困难的事。就像说打接球是由“智能”完成的，在某些语境下会觉得很怪似的，究竟什么算是人工“智能”难以准确定义。本文目的并非精确定义 AI，只要大家将其视为能够替代“人类智能活动”全般的机器（计算机），就能较好地把握这一概念。

由于将“人类智能活动”全盘囊括会涵盖极其广泛的领域，人工智能学会在其提供的 AI Map β2.0 中，如下图所示，对 AI 的课题领域进行了分类。

![AI 领域](/img/blogs/2025/0905_ai-overview/ai-area.jpg)

以接球为例，机器需要先识别“白色球体正在逐渐变大”，并分析出“球正向自己飞来”，接着预测“球的到达位置”，然后控制“手套的位置”，由此可见，智能活动包含了各种不同的侧面。

生成式 AI 是指聚焦于生成与对话等课题领域[^3]的 AI，特别是因其能够创造“新事物（如文本、图像、数据等）”，因而被寄予厚望，认为它或将替代人类“智能劳动”[^4]。

[^3]: 在生成内容时，它似乎也具备对输入信息进行“分析/推断”、并根据指令进行“设计”等领域的功能。但要把握概念，理解为主要具备“生成”功能即可。

[^4]: “或可替代智能劳动”的期待正是 AI 概念本身。笔者的直觉是，生成式 AI 所承载的期待之大，体现在真正从事智能劳动的人们怀有“自己或将被取代”的期待（或危机感），这点与以往“总有一天可能实现”式的 AI 梦想有所不同。

## 支持生成式 AI 的技术

在 AI 概念诞生之初，就有人提出了通过机器重现“人脑神经细胞运作”的神经网络（Neural Network）这一想法。人脑神经细胞（神经元）已知以“接收多路电信号输入后，将信号传递给下一个神经细胞”的方式反复活动。于是人们尝试将“以多个输入为基础输出信号”的神经元模型，如网络般组合起来，以此重现脑部功能。

![神经网络](/img/blogs/2025/0905_ai-overview/neural-network.jpg)

构建好的神经网络对给定输入产生输出，并通过依据输出调整网络参数的方式，逐步使其能输出“正确≒人类所期待”的结果。就如同人类通过试错来习得知识一般，这一参数调整阶段被称为 AI 的“学习”。

由于神经网络是尝试重现大脑机制的模型，因此根据如何表达大脑运作，会存在多种类型[^5]。所选模型不同，其特性也会变化；但无论哪种，都因网络状模型的性质而倾向于需要大量计算，受限于计算机性能，历经过数次兴衰后才得以进步。

[^5]: 著名的有，将网络多层堆叠以实现更深层学习（深度学习）的深度神经网络（DNN）；在图像处理等方面表现优越的卷积神经网络（CNN）；能处理时序数据、从而可进行语境解析的循环神经网络（RNN）等。

2017 年，Google 的研究者提出了名为 Transformer[^6] 的模型，与此前模型不同，它在评估序列数据关联性时引入了“注意力（Attention）”机制。该机制旨在提升机器翻译等从输入生成另一序列输出的“序列转换”性能，与之前的方法不同，它能够对庞大输入进行关联性评估，从而生成自然（合理）的输出。这种对大量信息依然能评估关联性的特性，结合计算机性能的持续进步，成为在生成领域广泛应用的基础。作为生成式 AI 的先驱之一，OpenAI 的 GPT（Generative Pre-trained Transformer）也是 Transformer 的衍生模型之一。

[^6]: 这篇题为“Attention Is All You Need”的论文，听起来像电影或歌曲名，但据说它对此后 AI 的演进贡献巨大，论文被引用次数也非常多。

能够对输入生成合理输出，也意味着通过对 AI 进行预先学习各种信息，AI 就能生成“新”的合理输出。比如，想象一个人大量学习了贝多芬的乐曲后，是否能创作出“如同贝多芬所作”[^7]的新曲？以近年来的技术体验来看，生成式 AI 的输出确实已相当接近人类创作。

[^7]: 正如孩子创作的“贝多芬风”曲子与专业音乐家创作的“贝多芬风”曲子的完成度不同一样，作品的合理程度会随创作者的理解深度而变化。因为它模仿了人类智能，所以对生成式 AI 而言，如何让它学习（成长）便成为关键，这一点也颇具趣味。

## 生成式 AI 的影响及其局限

随着生成式 AI 能承担近似人类的智能工作，诸如“查资料并撰写报告”或“分析需求并进行适当设计”等过去只能由人类完成的任务，计算机也开始有可能分担。毕竟一些人做起来很费时的工作，AI 能以相当快的速度完成[^8]，因此在这类工作上，利用生成式 AI 有望显著提升生产力。

[^8]: 你或许已经注意到，本文中的示意图是利用生成式 AI 制作的。由于笔者不够熟练，未能达到“完全如想象”的效果，但若以人工方式制作，这些插图至少也要花费数小时，而 AI 仅用了几分钟，因此其效能不言而喻。

但 AI 输出的内容并非“100%合理”。当对 AI 下达不佳指令[^9]时，常会有这种感受；此外还报告了所谓的“幻觉（Hallucination）”——输出不准确的信息，以及被称为“错配（Misalignment）”的“有害” AI 的出现。毕竟这是基于人脑的尝试，像人类一样，在“指令模糊时无法产出好结果”、或“无意中说出似是而非的谎言”、甚至“表现出违背伦理的行为”都属正常。

[^9]: 使用过生成式 AI 的朋友可能深有体会，对于“请将本文摘要为 100 字左右”这类较为明确的指令，它能给出相当不错的结果。然而对于“请恰当地介绍日本战国时代”这类输入过于庞大或要求不够明确的情况，其输出结果往往会有较大波动。

能够分担智能劳动，意味着人类的一部分工作有可能被生成式 AI 替代。比如，[ILO 报告](https://www.jil.go.jp/foreign/jihou/2025/07/ilo_02.html)就指出，四分之一的就业将受到影响。然而该报告也提到，人类的智能工作要被完全取代似乎仍很困难。

对于能否克服前述技术难题，笔者并非专家，难以妄加评断。但即便技术难题被攻克，AI 无法自主决策这一问题仍将存在。这并非 AI 能力上的技术问题，而是关于“AI 所做决策”的责任归属尚未达成共识的社会结构性难题。

笔者认为，目前社会的基础[^10]是：若由个人所为，其责任由当事人承担；若属于组织行为，则由组织（负责人）承担。也就是说，若 AI 输出导致问题出现，“责任如何承担”不明确， AI 就无法独立替代人的工作。或许在遥远的未来，我们会达成“因为是 AI 做的”这样的共识，但以现阶段感受，若发生问题，要将责任归咎于 AI，人们依然难以接受。

[^10]: 例如，对儿童行为的责任，监护人也要承担；为应对万一，还会投保等。在现今社会，似乎已将责任拆分到个人可承受的程度。虽非社会科学专家，仅是笔者的感觉，首要原则是由当事人承担责任，这也是社会得以运转的要素，换言之，是周边人能包容发生问题的理由。

## 我们应该如何与 AI 相处

笔者的经验也只是略微试用而已，但在现阶段，我更倾向于将生成式 AI 视为“（会努力完成任务的）新人”而非仅仅是“按指令产出合理结果的机器”。换言之，它会在得到“明确指令”后产出结果，但也会“出错”，因此需要审核，且一旦出错，需由下指令的一方承担责任。反过来，原本交给新人做的那些杂务，生成式 AI 或许也能替代。有美国等地智能劳动市场入门级职位减少[^11]的现象，或许正是生成式 AI 崛起（或人们对此的期待）的一个佐证。

[^11]: 由于还牵涉经济状况等因素，不能简单地说“AI 抢了工作”，但据说已有相当一部分管理者认为[简单任务和常规任务可由生成式 AI 替代](https://www.bloomberg.co.jp/news/articles/2025-06-09/SXLCF6DWLU6800)。

在工业革命时期，借助蒸汽机和内燃机等机械动力，将劳动密集型业务转向资本密集型业务。以道路施工为例，因机械动力极大提高了生产效率，原本需要大量劳动力（工人肉体劳动）的工作，转为集资（引入施工机械）后以少量劳动力完成。我认为未来在智能劳动领域也很可能发生类似的结构性变化。

![工作模式](/img/blogs/2025/0905_ai-overview/working-model.jpg)

乍看之下，减少经验浅者，仅由少数“资深人员”进行业务似乎最为高效。然而从长远来看，“资深人员”终将随时间退隐，维持业务持续性就会变得困难。考虑到将与 AI 分工，今后也需要推动人类在所担任角色上的技能成长。

以使用重机的道路施工为例，“决定在哪儿挖土在哪儿填土”是人类，“实际进行土方或搬运石块”的是机械，“在发生问题时考虑对策或进行调整”的又是人类，这样分工。在智能劳动领域也同样，虽然还有许多未知，但人类无法回避的领域将会继续存在。考虑到生成式 AI 无法“自主决策”且“无法承担责任”的特性，我觉得未来的智能劳动将要求人类具备“能决策并承担责任”的能力。

虽说笔者对教育领域也是外行，但我认为，让人“深入思考，在自己的责任范围内作出决策”[^12]，或提供这样的机会，将成为未来职业发展中重要的一环。

[^12]: 例如，作为公司职员等，最终决策权往往掌握在难以掌控的位置。但如果在负责的工作范围内，就“如何推进”进行评估/决策，并向上级申请批准的方式，就能轻松获得决策经验，不是吗？

## 总结

本文以笔者的外行理解，从背景到现阶段能力、再到未来展望，对生成式 AI 进行了整理。若能在“对生成式 AI 感兴趣但不知从何下手”的时候帮到您，我将深感荣幸。

本文未深入探讨各项技术细节，但在本开发者网站上，包括本接力连载在内，[也有诸多专家发声](/tags/生成ai/)，如有兴趣，欢迎前往阅读。
