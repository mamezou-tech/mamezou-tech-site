---
title: 让我们来谈谈统计 - 软件质量的统计入门（第10回 母体与样本：中心极限定理、大数定律）
author: shuichi-takatsu
date: 2025-06-09T00:00:00.000Z
tags:
  - Analytics
  - ソフトウェア
  - 品質
  - 新人向け
image: true
translate: true
---

## 引言

“如果能够调查一切，那就完美无缺，但现实中这是不可能的”  
——这不仅是质量管理的问题，而是所有调查和分析都共同面临的挑战。

在“让我们来谈谈统计”系列的第10回中，我们将介绍推断统计的基本概念“**母体**”和“**样本**”，并说明支撑推断统计核心的“**中心极限定理**”与“**大数定律**”。此外，我们还将从实际工作的角度，解读由此产生的**“抽样误差”和“偏差的风险”**。

例如：
- 在测试中记录了100个缺陷，但这真的能代表“整体的趋势”吗？
- 仅通过对某些模块的评审，就能推断整个项目的质量吗？

要面对这些问题，就需要具备“**从局部推断整体**”的思维方式。

在本文中，我们将以软件质量的案例为切入点，作为第一步，**揭示“为何不正确处理样本会导致判断错误”**。

---

## 什么是母体和样本？

“‘母体’和‘样本’感觉好难......”，正是希望你知道的推断统计基本知识。

在实际的业务或质量管理现场，**要确认所有数据（母体）是非常困难的**。  
因此，我们需要从其中一部分（样本）来推断整体特征——这种“从局部解读整体”的智慧。

例如：

- **母体（Population）**：作为调查对象的整体集合  
  例：过去1年内登记的所有 Bug 工单（总数：18,435 件）

- **样本（Sample）**：从母体中抽取的一部分数据  
  例：2025年4月发生的500条缺陷数据

将其图示表示为，

$$
\bar{x}_{\text{sample}} \approx \mu_{\text{population}}
$$

这个公式表示“即使只有部分数据（样本），也能在一定程度上推断整体（母体）的趋势”。  
从样本平均 $\bar{x}$ 来估计母体平均 $\mu$，是推断统计的基本。

![母体与样本](https://gyazo.com/cb7ef9fd84ffc96cf84910e33034cbe8.png)

就像“尝一口菜就判断整道菜的味道”一样。  
如果样本的“选择方式”或“获取方式”有问题，就会错误地判断母体的实际情况。

---

## 为什么能够从样本推断母体？

到目前为止我们已经多次零散地提到，现在来详细说明“**中心极限定理**”和“**大数定律**”。

刚才说过“可以从样本推断母体”，那是为什么呢？  
已知如果样本量足够大，样本的平均值或比例会趋近于母体的平均值或比例。  
这是由统计学的基础理论——**中心极限定理**和**大数定律**所支撑。

### ● 中心极限定理（Central Limit Theorem）

那么，实际中“样本平均趋近于母体平均”这一现象是如何发生的，让我们来看看。

即使母体的分布严重偏斜，**只要样本量足够大，样本平均的分布就会趋近于正态分布**，这是统计学中非常重要的性质。

这个性质就是由**中心极限定理**来解释的。  
- **无论母体的分布如何，只要样本量足够大（例如：$n \geq 30$），样本平均的分布就会趋近于正态分布。**

换言之，即使原始数据有偏，也可将其平均值的分布视为正态分布。  
这样就能使用**基于正态分布前提的统计方法（估计和检验等）**。

> 例如：即使缺陷修复时间分布偏斜，只要取足够多的样本，**其平均值也会趋近于正态分布**

下图从视觉上展示了中心极限定理（Central Limit Theorem）。  
- 左：**母体分布（指数分布）**  
- 右：**样本平均分布（取 $n = 30$ 的样本 1000 次）**

![中心极限定理](https://gyazo.com/ae33e321d51d2add8b0ec87efadb6c0e.png)

#### 左：母体（偏斜分布）

- 使用的是 **指数分布**（向右偏斜的分布）  
- 小于平均值的数据较多，较大数值偶尔出现  

→ 这种分布显然**不是正态分布**。

#### 右：样本平均的分布（$n = 30$ 的样本 1000 次抽取）

- 从偏斜的母体中抽取 $n=30$ 的样本 1000 次，计算每次的平均并绘制分布。  
- 结果呈现出**近似正态分布的形状（左右对称、集中在中心）**。  

→ 这表明了中心极限定理“样本平均的分布会趋近于正态分布”的性质。

#### 从图中可以看出

从上述“母体”和“样本”的关系可以看出，即使原始数据**不是正态分布**，只要样本量足够大（如 $n \geq 30$），**样本平均的分布就会趋近于正态**（即中心极限定理）。

#### 在实际工作中的意义

即使缺陷密度、修复时间、响应时间等**存在偏斜**，也可以对其**平均值进行基于正态分布的统计分析（置信区间、检验等）**。  
这为“为何可以以正态分布为前提？”这一疑问提供了直观且有力的支持。

### ● 大数定律（Law of Large Numbers）

现在，刚才解释了“样本平均趋近于母体平均”，  
我们进一步探究“为什么会这样？”的依据。

如果不只看单个样本，而是例如连续多次掷骰子并记录平均值，会发生什么？  
次数少时平均值会有较大波动，但随着次数累积，平均值会收敛到某一数值。

保证这一现象在理论上成立的就是**大数定律**。  
- **样本量越大，样本平均就越接近母体平均**

也就是说，它保证了“随着观测次数的增加，平均值会接近真实值”的规律。

下图从视觉上展示了大数定律（Law of Large Numbers）。  
- 蓝线：累计得到的样本平均  
- 红色虚线：真实母体平均（μ = 100）

![大数定律](https://gyazo.com/09473f1d17fc424a8df973862094136b.png)

#### 解读方式：

- 当样本量较小时，平均值波动较大（上下剧烈抖动）  
- 随着样本量的增加，平均值**收敛到红色虚线（母体平均）**

该图直观地展示了“大量数据越多，平均值越接近真实平均”的大数定律。

#### 从图中可以看出

可以看出平均值具有“虽有波动，但会逐渐接近真实值”的特性。  
**一次观测无法保证准确性，但重复观测则可提高精度**。  
之所以能在实际工作中使用统计估计（如置信区间），正是因为**有这种收敛性保障**。

#### 在实际工作中的意义

不要对少量数据反应过度，关键是要**确保一定的样本量**。  
例如，不要仅通过一次观察来判断模块的缺陷密度，而应汇集多个模块的**平均缺陷密度**来进行判断，这是统计学方法。

上图直观地回答了“为何能够从样本推断母体”的问题。

:::info
大数定律是关于“精度”（能够多接近真实值），  
中心极限定理是关于“形状”（分布趋于正态形）。  
两者都是统计推断的基石。  
:::

### ● 这两条定律的含义

单凭少量样本得出结论是非常危险的，因为**中心极限定理无法发挥作用，平均值的分布无法呈现正态**。  
反之，使用的数据（样本）越多，**对平均值或比例的估计越接近“母体的真实值”，可信度也越高**。  
在实际工作中使用的“置信区间”和“显著性检验”等统计方法，都基于这两条定律（中心极限定理和大数定律）。

---

## 为什么要使用样本？

全数调查（检查母体的所有数据）是理想状态，但实际上由于以下原因很困难。

- **成本、时间、人员资源的限制**  
  例如，分析所有 18,000 条 Bug 工单需要大量时间和人力。

- **对实时性的需求**  
  在质量管理现场，需要“立即把握当前状态”。  
  使用样本，可在**有限时间内快速做出判断**。

- **通过适当抽样，可充分推断整体情况**  
  根据统计学理论，使用**随机且无偏的样本**，能够高精度地估计母体特征（平均值、比例等）。

总之，“无需调查全部，只要巧妙地选择‘代表’，就能做出充分判断”，  
这就是统计学中“样本”的威力。

---

## 什么是推断统计？

[“让我们来谈谈统计”第1回](/zh-cn/2025/05/27/lets_talk_statistics_shall_we_01/)中，已解释了描述统计和推断统计的概要。  
在第9回之前，主要基于描述统计，介绍了“直接观察”数据特征的方法。  
从这里开始，我们将探讨**“从一部分（样本）推断整体（母体）”**的方法，  
即**推断统计（Inferential Statistics）**。

### ● 描述统计 vs 推断统计（回顾）

| 类型       | 主要目的                      | 数据对象            | 使用场景             |
|------------|-------------------------------|------------------------|----------------------|
| 描述统计   | 数据摘要与整理             | 手头上的全部数据   | 把握情况、可视化趋势 |
| 推断统计   | 估计与判断母体性质       | 部分数据（样本）   | 未来预测、决策      |

在推断统计中，可进行以下估计和判断：

- 从样本平均估计**母体平均 $\mu$**  
- 从样本比例估算**整体的趋势和比例**  
- 判断结果是否偶然  

“由于无法调查全部，要考虑能从样本中‘以多大程度’进行准确估计”，  
这就是推断统计的入门。

---

## 抽样方法与偏差

常说“样本应是‘母体的代表’”，  
但**如何选择“有意义的样本（具有代表性的数据）”**将直接影响**推断本身的可信度**。

在此介绍常见的抽样方法以及需注意的偏差。

### ● 随机抽样（无作择抽取）

从母体中**以等概率随机抽取**。  
此法不易产生偏差，是最基本且值得信赖的方法。  

示例：从 1000 条 Bug ID 中随机抽取 100 条

```python
import random

# 准备1000个Bug ID（BUG-0001 ～ BUG-1000）
all_bugs = [f"BUG-{i:04d}" for i in range(1, 1001)]

# 随机抽取100个
sample = random.sample(all_bugs, 100)

# 排序后仅显示前10个
print("抽出されたバグID（上位10件）：")
for bug in sorted(sample)[:10]:
    print(bug)
```

输出如下：

```text
抽取的 Bug ID（前10条）：
BUG-0007
BUG-0016
BUG-0108
BUG-0122
BUG-0123
BUG-0130
BUG-0135
BUG-0140
BUG-0143
BUG-0148
```

### ● 分层抽样（Stratified Sampling）

将母体**按属性划分为若干层，然后从各层均等抽取**。  
这样能确保少数类别的意见也被体现，提高代表性。

示例：  
- 从项目 A、B、C 中各抽取20条  
- 针对缺陷类别（UI/性能/故障）各抽取15条  

下面的示例假设项目 A、B、C 这3个层中各有40条 Bug ID，并进行从每层随机抽取10条的分层抽样。

```python
import random
import pandas as pd

# 为各层（项目）准备40条Bug ID
strata = {
    "Project A": [f"A-{i:03d}" for i in range(1, 41)],
    "Project B": [f"B-{i:03d}" for i in range(1, 41)],
    "Project C": [f"C-{i:03d}" for i in range(1, 41)],
}

# 从各层随机抽取10条（分层抽样）
stratified_sample = []
for project, bugs in strata.items():
    sample = random.sample(bugs, 10)
    stratified_sample.extend((project, bug_id) for bug_id in sorted(sample))

# 将结果显示为DataFrame
df = pd.DataFrame(stratified_sample, columns=["層（プロジェクト）", "バグID"])
print(df)
```

运行结果（从各项目中各抽取10条）如下：

```text
      层（项目）   Bug ID
0     Project A  A-006
1     Project A  A-009
2     Project A  A-011
...
13    Project B  B-010
14    Project B  B-024
...
28    Project C  C-037
29    Project C  C-039
```

就这样，通过分层抽样能够确保将少数群体（层）也纳入样本，从而获得具有高度代表性的样本。

### ● 偏差的例子与风险：选择方式一旦偏颇，世界就会扭曲

抽样最可怕之处在于，一不小心就会得出“对自己有利的结论”。

#### ■ 常见选择偏差的例子

- “仅调查质量较差时期的数据”  
  → 看起来比实际更差（负向偏差）  
- “只挑选成功案例”  
  → 看起来比实际更好（正向偏差）

这往往在无意之间发生，是**“由偏颇数据导出偏颇结论”**的典型案例。

### ● 样本抽取决定“结果本身”

- **是随机选择？还是考虑分层？**  
- **从哪个时间段、哪个视角进行选择？**

这些判断将大大影响结论的可信度。要进行有意义的统计推断，**必须具备选择样本的技术（抽样）以及对其风险（偏差）的理解**。

**■ 错误抽样案例：对评审质量的高估**

在某项目中，有个团队试图评估代码评审的质量。  
他们打算“从评审记录中抽取数据，计算评审指出数的平均值”，以验证改进效果。

但他们**所抽样的对象是“仅限资深工程师的评审记录”**。

**■ 结果：**

- 平均指出数非常少，于是得出“质量非常高”的结论  
- 然而，在新人成员的评审中，**存在大量遗漏和形式化指出**

→ 因此，评价结果与实际团队整体的评审质量相差甚远。

该案例的失败在于抽样了“缺乏代表性的样本”（即未考虑分层，仅针对某个偏颇子群体）。

**错误的样本选择将直接导致错误的判断。**  
抽样不仅是简单的“数据提取”，更是**影响决策的统计判断入口**。

---

## 实务中的注意事项

- **样本的“代表性”是一切的前提**  
  - 如果样本选择有偏，那么结论也会随之偏颇

- **务必记录并报告“抽取方法”、“调查对象的时间范围”等元信息**  
  - 若调查条件不明，后续无法重现或重新解读

- **以误差（波动）不可避免为前提**  
  - 抽样误差无法消除，因此在事先包含误差范围进行说明，是**统计推断的基本做法**

例如，  
“不良发生率为 3.2% ± 0.4%”  
以**“估计值 ± 误差”**的形式呈现，会让接收者更易于判断。

理论上定义该“误差范围”的，就是**置信区间**（下次将讨论）。

---

## 软件质量现场案例

至此，我们讨论了“不正确选择样本会导致判断错误”，  
在实际的软件质量管理现场，  
**如何根据目的设计母体和样本的关系**也极其重要。

例如：  
- 是检查所有的评审记录？还是只针对特定成员的记录？  
- 是以所有故障报告为对象？还是只关注重大故障？

这样的设计将大大影响**分析的视角与结果的应用方式**。

下面的表格展示了在软件质量的背景下，“母体·样本·目的”如何关联的具体案例。

| 母体                     | 样本                       | 抽取目的             |
|--------------------------|----------------------------|----------------------|
| 过去3年内的所有故障报告 | 过去6个月的重大故障       | 趋势变化的早期发现   |
| 所有的代码评审记录       | 新成员的评审记录           | 教育效果分析         |
| 每日执行的自动化测试日志 | 每周随机抽取的日志         | 掌握测试质量的长期趋势 |

如此，“以何为对象，以及如何切分”，将决定分析结果本身。  
处于分析“前端”的“样本设计”，正是统计质量管理中极其重要的技能。

---

## 总结

在本文中，我们学习了作为统计推断出发点的“母体”和“样本”之间的区别，  
以及将它们连接起来的理论“中心极限定理”和“大数定律”。

- “样本（Sample）”是从母体的一部分获得的数据  
- 样本平均 $\bar{x}$ 是近似母体平均 $\mu$ 的估计量  
- 这并非偶然，而是由“中心极限定理”和“大数定律”支撑的**数学依据**

此外，以下实务上的注意事项也很重要：

- **样本的选择（抽样）决定了结果本身**  
- 缺乏随机性的样本或偏斜数据会**导致错误判断或过度自信**  
- 需要利用**分层抽样**等方法选择“具有代表性的数据”  
- 若对偏差（选择性偏袒）缺乏意识，将损害分析的可信度

用一句话概括**“如果无法调查全部，就需要‘巧妙选择的能力’”**  
——这就是推断统计的本质。

---

## 下期预告

下期我们将学习回答“可以相信到什么程度？”这个问题的**置信区间与误差的思路**。

[此处汇总了统计相关信息。](/analytics/)

希望对您的数据分析有所帮助。

<style>
img {
    border: 1px gray solid;
}
</style>
