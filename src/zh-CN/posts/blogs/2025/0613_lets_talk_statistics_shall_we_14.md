---
title: 让我们来谈谈统计吧 - 面向软件质量的统计入门（No.14 预测：通过回归分析解读质量）
author: shuichi-takatsu
date: 2025-06-13T00:00:00.000Z
tags:
  - Analytics
  - ソフトウェア
  - 品質
  - 新人向け
image: true
translate: true

---

## 引言

“让我们来谈谈统计吧”第14期中，我们将使用**回归分析**这一方法来尝试“预测未来”。  
在本系列中，我们通过过去的数据把握整体图景和变量关系，而这一次将利用这些见解，学习如何**用具体数值来预测未来的发展**。

例如——  
- 根据过去的测试工时与缺陷数量的关系，估算今后的缺陷数  
- 根据模块的代码行数，预测评审指出的问题数  
- 通过响应时间的变化，预测用户满意度的下降

这样看来，**回归分析是从“关系性”迈向“未来推断”的统计工具**。  
在软件质量实践中，除了经验法则，在更多场景下，**定量化的预测**正支撑着决策。

本次将聚焦回归分析的基础“单回归分析”，并从理论到实践，再到Python实现，进行简明扼要的讲解。  
希望能让大家感受到：“统计也可以用于预测！”

---

## 什么是回归分析？

**回归分析**是一种通过其他变量（解释变量）来**预测**某个变量（目标变量）的统计方法。  
单纯的相关分析仅限于把握“有关系/无关系”等趋势，而回归分析则将这种关系建模为数式，从而能够**对具体数值进行估计和预测**。

例如——

- 如果了解测试工时（解释变量），就可以预测未来的缺陷数量（目标变量）  
- 如果知道模块的代码行数或复杂度，就可以估算评审指出的问题数与缺陷数  
- 将开发者的技能或经验年限与缺陷发生的关系建模，以分析团队风险

这样，回归分析通常用于以下目的：

1. **预测**  
   根据解释变量的值，预测目标变量的值。  
   例如：  
   - 模块的代码行数 → 预测该模块潜在的缺陷数量  
   - 测试设计工时 → 预测将被发现的缺陷数

2. **因素分析**  
   定量评估不同解释变量对目标变量的影响程度。  
   例如：  
   - 比较复杂度、代码量、开发者技能对缺陷数量的影响程度

:::info
该方法不仅是统计学的基本手段，近年来也被用作**机器学习中预测建模的基础**。由于其精度高且易于解释，因此在软件质量分析中也是常见的分析方法。
:::

---

## 单回归分析：最基本的回归模型

回归分析有多种类型，其中最基本的是**单回归分析（simple linear regression）**。  
它是一个非常简单的模型，用于“从一个解释变量（X）预测一个目标变量（Y）”。

单回归分析的基本公式如下：

$$
Y = \beta_0 + \beta_1 X + \varepsilon
$$

各符号含义如下：

- $Y$：想要预测的变量（目标变量）  
- $X$：解释变量（用于预测的变量）  
- $\beta_0$：截距（当X为0时的Y预测值）  
- $\beta_1$：回归系数（当X增加1个单位时Y的变化量）  
- $\varepsilon$：误差项（模型无法解释的偏差）

该公式在假定X和Y之间存在线性关系的前提下，拟合一条用于预测的“直线（回归直线）”。  
直观上，其目的是通过“在数据散点图中画出最适合的那条直线”，从而能够从X预测Y。

### ● 回归式的求解方法（最小二乘法）

那么，如何找到这条“最适合”的直线呢？  
答案就是**最小二乘法（Least Squares Method）**。

#### 残差及其最小化

“残差”是指每个数据点的**实际观测值与回归直线预测值之间的偏差**。

$$
\varepsilon_i = y_i - (\beta_1 x_i + \beta_0)
$$

通过调整回归直线，使残差尽可能小。  
但如果仅仅对残差求和，正负值会相互抵消，所以要使**残差平方和**最小化：

#### 最小化目标

$$
\text{目标：} \quad \sum_{i=1}^{n} (y_i - \beta_1 x_i - \beta_0)^2 \quad \text{最小化}
$$

通过这种方式，可以得到一条使所有数据点与直线之间的偏差最小化的最优直线。  
数学上可以通过微分推导出 $\beta_0$（截距）和 $\beta_1$（斜率），但使用Python等工具则可以自动计算。

:::info
● 实务要点  
“通过最小二乘法得到的回归直线”并不一定能完美拟合所有数据。  
但是，它是一种非常有效的手段来把握“整体趋势”。  
要确认其有效性，下一章将介绍的**决定系数（$R^2$）和残差分析**非常重要。  
:::

### ● 示例：从测试工时预测缺陷数量

在软件开发中，可以假设测试所耗费的工时（时间或人日）与发现的缺陷数量之间存在一定关系。  
下面以过去的项目数据为例，展示如何构建一个从测试工时预测未来缺陷数量的模型。

使用的过去数据  
| 测试工时（人日） | 缺陷数量（件） |
|-----------------|----------------|
| 5               | 4              |
| 10              | 6              |
| 15              | 10             |
| 20              | 14             |
| 25              | 16             |

基于这样的数据，进行线性回归模型的预测。

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# 日文字体设置（适用于 Windows 环境）
plt.rcParams['font.family'] = 'Meiryo'

# 过去数据（示例：测试工时 [人日] 和缺陷数量）
x = np.array([5, 10, 15, 20, 25]).reshape(-1, 1)  # 解释变量：测试工时
y = np.array([4, 6, 10, 14, 16])                  # 目标变量：发现的缺陷数量

# 创建并训练单回归模型
model = LinearRegression()
model.fit(x, y)

# 获取回归系数和截距
a = model.coef_[0]
b = model.intercept_
print(f"回帰式：バグ件数 = {a:.2f} × テスト工数 + {b:.2f}")

# 预测和可视化
x_pred = np.linspace(0, 30, 100).reshape(-1, 1)
y_pred = model.predict(x_pred)

plt.scatter(x, y, label='実測値（観測データ）', color='blue')
plt.plot(x_pred, y_pred, label='回帰直線', color='red')
plt.xlabel('テスト工数（人日）')
plt.ylabel('バグ件数')
plt.title('テスト工数とバグ件数の回帰分析')
plt.legend()
plt.grid(True)
plt.show()
```

执行上述程序后，输出了如下结果：  
![测试工时与缺陷数量的回归分析](https://gyazo.com/dc71988abf60b42b293ca77841b7389f.png)

在这个示例中，假设测试工时越多，发现的缺陷数也越多，即存在正相关关系。  
当然，现实中还会受到测试质量、需求难度等其他因素的影响，但作为聚焦于单一因素的简易预测模型仍然有效。  

---

## 回归模型的拟合程度：决定系数

用于评估所建立的回归模型“拟合程度（即有多大帮助）”的指标即为**决定系数（$R^2$）**。

- $R^2$ 的取值范围为 0~1，值越接近 1，表示模型的**解释力**越强。

例如，当 $R^2 = 0.75$ 时：  
- 可以这样解读：“Y 的变异有 75% 可由 X 来解释”。  
- 剩余的 25% 则可认为是由未使用的其他变量或随机误差造成的。

### ● 实务中的应用要点

决定系数是客观评估“预测可信度”的基准线。  
但**仅凭 $R^2$ 较高并不一定是“好模型”**，需要结合其他指标进行判断。

#### Python 中的验证示例（续）

```python
r2 = model.score(x, y)
print(f"決定係数 R^2 = {r2:.2f}")
```

计算上述代码后，结果为“决定系数 $R^2$ = 0.98”。  
通过这种方式，可以用数值来确认模型与实际数据的拟合程度。

:::info
● 为什么仅凭 $R^2$ 并不能说明是“好模型”？  

决定系数 $R^2$ 是衡量“模型对目标变量（$Y$）变异的解释程度”的**解释力指标**。  
然而，即使 $R^2$ 很高，也不一定就是好模型。原因如下。  

・仅凭 $R^2$ 无法判断的原因  

1. **模型的假设可能被破坏**  
   - 如果残差存在偏倚或受极值强烈影响，即使 $R^2$ 很高也无法信赖。  

2. **过拟合（Overfitting）**  
   - 特别是在多元回归分析中，增加解释变量往往能提高 $R^2$，但不一定提高预测精度。  

3. **忽视了非线性关系**  
   - 如果真实关系是非线性的，用线性模型进行拟合可能会导致 $R^2$ 同样上升。  

・那么，应使用什么方法来验证呢？  

要检验模型的合理性，需要结合以下方法：  

1. **残差分析（Residual Analysis）**  

- 检查残差图是否存在模式（线性性）  
- 残差的变异是否一致（等方差性）  
- 残差的分布是否接近正态分布（正态性）  
- 是否存在极端值  

2. **Adjusted $R^2$（自由度调整后决定系数）**  

- 考虑解释变量个数，对 $R^2$ 进行补正，**避免无意义的升高**  
- 在多元回归模型中尤其是必需的指标。  

3. **交叉验证（Cross Validation）**  

- 将数据划分为训练集和验证集，**验证对未知数据的泛化能力（预测能力）**  

4. **与领域知识的结合**  

- 评估模型输出在实际中是否能**导出合理的解释或可行的操作**  
- 例如：“测试时间翻倍导致缺陷数增加10倍”在实际中不合理 → 提示需要重新审视模型  

・总结  

**$R^2$ 是表示“拟合程度”的指标，并不保证“正确性”或“可靠性”。**  
**应结合残差分析、交叉验证、Adjusted $R^2$ 及领域知识，综合评估模型。**  
:::

---

## 验证模型合理性：残差分析

要验证模型不仅“拟合度好”，而且**统计上构建是否正确**，就必须进行**残差分析（residual analysis）**。

残差是实际观测值与回归模型预测值之间的差：

$$
\varepsilon_i = y_i - \hat{y}_i
$$

在理想的回归模型中，残差应“随机分布”＝**没有模式**，这很重要。

### ● 残差分析应确认的要点

- **检查残差图中是否存在趋势或模式**（曲线偏倚、异常分布等）  
- **残差的正态性**（通过直方图或 Q-Q 图确认是否服从正态分布）  
- **等方差性（同方差性）**（残差相对于预测值的分布是否一致）  
- **是否存在异常值**（是否有极端大的残差）

#### 使用 Python 绘制残差图（续）

```python
import seaborn as sns

# 计算残差
y_pred = model.predict(x)
residuals = y - y_pred

# 残差图
plt.scatter(y_pred, residuals)
plt.axhline(y=0, color='red', linestyle='--')
plt.xlabel('予測値')
plt.ylabel('残差')
plt.title('残差プロット')
plt.grid(True)
plt.show()
```

![残差图](https://gyazo.com/abef2c5ccea3bb722ab162a239281833.png)

根据上图对要点进行评估。  
| 评估视角               | 评估        | 评论                                                           |
|------------------------|-------------|----------------------------------------------------------------|
| 残差图的趋势或模式     | 〇 无问题   | 残差相对于预测值随机分布，未观察到明显的曲线趋势。             |
| 残差的正态性           | △ 待验证    | 仅凭此图无法判断残差分布是否服从正态分布，需要 Q-Q 图等进一步验证。 |
| 等方差性（同方差性）   | △ 稍显不稳定 | 残差相对于预测值的波动略有变化，建议通过检验进行确认。         |
| 是否存在异常值         | 〇 无问题   | 未观察到极端大的残差，整体上模型拟合良好。                     |

从该残差图可以看出以下需改进或确认的点：  
- 虽然未见残差有明显模式，但仍需确认等方差性和正态性。  
- 应通过 Q-Q 图或 Breusch-Pagan 检验验证模型假设的合理性。  
- 如有必要，也可考虑多项式回归或添加特征。

### ● 实务总结

即便决定系数很高，**若残差存在模式，模型也可能不可靠**。  
因此，检查模型合理性时，“决定系数（$R^2$）”和“残差分析”应始终结合使用。

---

## 多元回归分析：当存在多个解释变量时

在实际场景中，影响质量或缺陷发生的因素往往不止一个。  
例如，不仅是“测试工时”，还可能涉及“负责人熟练度”、“需求复杂度”、“是否进行评审”等多个因素的交叉影响。  
因此，需要同时处理多个解释变量的**多元回归分析**。

多元回归模型的一般形式如下：

$$
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_k X_k + \varepsilon
$$

此处注意事项：

- **多重共线性**：若解释变量之间高度相关，各系数的估计会不稳定。  
  例如：当评审次数与测试工时始终成正比时，无法区分各自的影响。  
- **自由度调整后决定系数（Adjusted $R^2$）**：当变量数量较多时，单纯的 $R^2$ 易被高估。  
  使用 Adjusted $R^2$ 可**更可靠地比较模型解释力**。  
- **实务意义验证**：即使解释变量在统计上显著，对于实际难以改进或控制的变量（例如：开发期间的天气）也应考虑排除。

### ● 模型改进的视角

- **选择与目标变量可能存在因果关系的解释变量**至关重要。  
- 通过 VIF（方差膨胀因子）进行多重共线性的定量评估，并在必要时考虑变量缩减（如逐步回归法）。  
- 通过残差分析和交叉验证，切勿忘记**避免过拟合**和**确认泛化能力**。

:::info
● **什么是 VIF（方差膨胀因子）？**  
**VIF（Variance Inflation Factor）** 是用于定量评估多重共线性（解释变量之间相关性）程度的指标。  
某个变量 $X_i$ 的 VIF 定义如下：

$$
\text{VIF}_i = \frac{1}{1 - R_i^2}
$$

其中 $R_i^2$ 是将 $X_i$ 关于其他解释变量进行回归时得到的决定系数。  
VIF 的参考值如下：

| VIF 值  | 解释                                    |
|---------|-----------------------------------------|
| 1.0〜2.0 | 无问题                                   |
| 5以上    | 存在多重共线性疑虑                        |
| 10以上   | 多重共线性严重，模型不稳定               |

**要点**：VIF 较高的变量与其他解释变量高度相关，可能对多元回归模型的系数估计产生不利影响。

● **什么是变量缩减（如逐步回归等）？**  
在多元回归分析中，过多的解释变量可能导致**过拟合或可解释性下降**。  
因此，通过**变量选择方法（变量缩减）**来挑选所需的最少解释变量非常重要。

・主要的变量选择方法  
| 方法           | 概述                                                                 |
|----------------|----------------------------------------------------------------------|
| **逐步回归法** | 结合前向选择法和后向剔除法，在添加或删除解释变量的过程中探索最优模型      |
| **前向选择法** | 逐个添加解释变量，仅当模型得到改善时才采用                              |
| **后向剔除法** | 初始使用所有变量，并逐步删除影响较小的变量                              |

**要点**：在选择变量时，可利用 AIC、BIC、Adjusted $R^2$ 等模型评价指标，构建更可靠的模型。  
:::

多元回归分析是捕捉实务中“多因素交织的复杂现象”的基本工具。  
在质量管理场景中，也常用其同时评估“生产条件”、“测试方法”等多个因素的影响。

---

## 回归分析的局限与注意事项（实际工作中常见的陷阱）

回归分析虽是非常有用的工具，但在使用时需要理解一些**重要的局限与注意事项**。

### ● 并非因果关系

**存在相关性并不意味着必然存在因果关系。**

- 例如：即使冰淇淋销售量与中暑发生率存在相关，也不能说两者具有因果关系（二者背后可能有共同因素“气温升高”）。

⇒ 在实际工作中，**具备因果推断的视角（例如：干预或控制）非常重要**。

### ● 对外插不稳健（注意模型的适用范围）

**超出观测数据范围的预测（外插）可能会导致精度大幅下降。**

- 模型始终基于“已观测范围”内的规律性。  
- 应用于未知领域时，可能会产生不合理的预测。

⇒ **在实际应用中应时刻关注“数据的有效范围”。**

### ● 数据质量至关重要（Garbage In, Garbage Out）

**如果输入数据的准确性与可靠性不佳，模型结果也必然不佳。**

- 如果忽略缺失值、异常值、输入错误等预处理，就会得到不可靠的分析。  
- 特别是在质量管理场景中，还需注意**测量误差和数据收集条件的差异**。

⇒ **在分析前，进行“数据清洗”和“EDA（探索性数据分析）”是必不可少的。**

:::info
● **什么是数据清洗（Data Cleansing）？**  
用于分析的数据往往包含**采集错误、输入错误、缺失值、异常值**等，若不处理则无法进行高可靠性的分析。  
因此，需要进行以下**“清洗处理”**：

- 检查并处理缺失值（NaN）（删除或补全等）  
- 检测并处理异常值/离群值（例如：超过 3σ 的值等）  
- 统一数据类型（例如：数值被当作字符串处理）  
- 检查数据重复与一致性（例如：相同 ID 重复、矛盾值剔除）  

・**要点**：  
清洗是防止“垃圾输入导致垃圾输出” (Garbage In, Garbage Out) 的第一步。

● **什么是 EDA（探索性数据分析：Exploratory Data Analysis）？**  
EDA 是在分析前通过可视化和汇总来了解数据的**结构、分布、趋势和异常**的过程。  
目的是在分析前直观地理解“这些数据中发生了什么”。  

主要方法：  

- 使用直方图、箱线图、散点图可视化分布  
- 通过相关系数矩阵俯瞰变量之间的关系  
- 按分组汇总或分割（例如：按阶段、按负责人）以确认趋势  

・**要点**：  
EDA 也有助于验证**统计模型的前提假设（线性性、正态性等）**。  

通过认真执行这些步骤，可以大幅提高分析的精度、可靠性和解释力。  
在应用回归分析或机器学习模型前，**务必留出“与数据对话的时间”**。  
:::

### ● 补充：其他注意事项

- **样本量不足**：数据量少时易发生过拟合或统计不稳定性。  
- **忽略非线性关系**：可能存在线性模型无法表达的复杂关系。  
- **过度信赖模型的风险**：即使模型精度高，也不一定能用于商业决策（需要评估可解释性和可操作性）。  

---

## 相关与回归的区别

| 视角       | 相关                               | 回归                                     |
|------------|------------------------------------|------------------------------------------|
| 目的       | 观察变量间关系强度                 | 使用数式模型定量化“预测”与“影响量”        |
| 输出       | 相关系数（$r$）                    | 回归式（$Y = aX + b$ 等）                |
| 解释方向   | 对称（X 与 Y 角色等同）            | 非对称（X 为解释变量，Y 为目标变量）      |
| 因果暗示   | 无                                 | 不一定表示因果，但对假设构建有用          |
| 应用示例   | 质量指标间的关联性调查             | 缺陷数量预测、工时估算等                  |

### ● 什么是相关？

- 相关表征“两个变量在多大程度上共同变化”。  
- 相关系数 $r$ 的取值范围为 −1〜+1，值越大表示线性关系越强。  
- 但**存在强相关并不等同于存在因果关系**。

### ● 什么是回归？

- 回归分析是一种从“一个变量（解释变量）构建模型来预测另一个变量（目标变量）”的手段。  
- 单回归使用一个解释变量，多元回归使用多个解释变量来预测目标变量。  
- 在实际工作中，广泛用于“质量预测”、“工时估算”、“可靠性分析”等。  

:::info
即使存在相关，也不一定意味着有因果关系。使用回归分析时，也要注意对变量间关系的**意义解读**。  
例如：即便“测试工时”与“缺陷数量”存在相关，也不能仅此就断定二者有因果关系，应考虑是否存在外部因素。  
:::

---

## 软件质量中的应用案例（回归分析的应用）

回归分析也是软件质量管理和项目管理中的有效工具。  
以下展示几个典型的应用案例。

### ● 缺陷预测

- **概述**：以模块的代码量（LOC）、变更次数、复杂度等度量指标作为解释变量，预测未来的缺陷数。  
- **目的**：提前识别质量可能下降的模块，通过重点评审和测试，提高质量并降低成本。

### ● 工时估算

- **概述**：根据页面数、需求数、功能点数等开发规模指标，预测设计、实现、测试等各阶段的工时。  
- **目的**：利用过去的实际数据，实现更客观且高度可重现的估算，帮助**减少估算偏差**和**提升流程管理**。

### ● 风险分析

- **概述**：基于过去项目的实际情况和缺陷历史，提取并预测**缺陷趋势**和**延期风险**较高的模式。  
- **目的**：事先把握未来缺陷发生或延期的风险，计划性地采取早期应对和质量提升措施。

---

## 总结

回归分析是对软件质量数据进行“定量预测未来”的有力工具。  
但若轻率应用，也可能导致误解，因此**统计前提的验证**与**与领域知识的结合**是不可或缺的。

- 回归分析是“数值预测”的有用手段  
- 单回归是最基本的模型，在实际工作中也常被使用  
- 在使用时要注意与相关性的区别及因果关系

---

## 下次预告

下次第15期将作为本系列的总结，介绍**统计质量管理的实际应用**。  

[这里汇总了统计相关信息。](/analytics/)

希望对您的数据分析有所帮助。

```html
<style>
img {{
    border: 1px gray solid;
}}
</style>
```
